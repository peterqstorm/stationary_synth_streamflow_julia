{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kirsch-Nowak_Streamflow_Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted by Peter Storm (pqs4@cornell.edu) into Julia from MATLAB code written by Matteo Giuliani, Jon Herman and Julianne Quinn and located here: https://github.com/julianneq/Kirsch-Nowak_Streamflow_Generator\n",
    "\n",
    "A full description of the theory behind the model can be found here: https://github.com/julianneq/Kirsch-Nowak_Streamflow_Generator/blob/master/ModelDescription.pdf\n",
    "\n",
    "This is a Jupyter Notebook adaptation of the Kirsch-Nowak Streamflow Generator for stationary hydrology. For full documentation, please visit the following page: https://github.com/julianneq/Kirsch-Nowak_Streamflow_Generator/tree/master/stationary_generator\n",
    "\n",
    "*Please note that this model has not been validated at this time; it appears that there may be some errors in the outputs. Please contact me or flag an issue on GitHub if you are aware of what the issues may be.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "#note that if you need to install a library, use the following two lines\n",
    "#using Pkg\n",
    "#Pkg.add(\"name\")\n",
    "using Base\n",
    "using CSV\n",
    "using Tables\n",
    "using LinearAlgebra\n",
    "using Statistics\n",
    "using ElasticArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cholesky_corr (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cholesky_corr(Z)\n",
    "    # Computes the cholesky decomp of correlation matrix of columns of Z\n",
    "    # Then attempts to repair non-positive-definite matrics\n",
    "    # Code adapted from https://github.com/julianneq/Kirsch-Nowak_Streamflow_Generator/blob/master/stationary_generator/chol_corr.m\n",
    "    # http://www.mathworks.com/matlabcentral/answers/6057-repair-non-positive-definite-correlation-matrix\n",
    "    # rank-1 update followed by rescaling to get unit diagonal entries\n",
    "    \n",
    "    R = Statistics.cor(Z)\n",
    "    U = cholesky!(R, check=true)\n",
    "\n",
    "    #check if positive definite, otherwise modify slightly until true\n",
    "    while issuccess(U) == false\n",
    "        k = min([real(eigh(R)) - 1 * eps()])\n",
    "        R = R - k * Matrix{Float64}(I, size(R), size(R))\n",
    "        \n",
    "        R = R / R[1, 1]\n",
    "        U = cholesky!(R)\n",
    "    end\n",
    "\n",
    "    return U.U\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convert_data_to_monthly (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function convert_data_to_monthly(Qt)\n",
    "    num_years = Int(floor(size(Qt, 1) / 365))   #first dimension of input array\n",
    "    num_sites = size(Qt, 2)\n",
    "\n",
    "    \n",
    "    num_months = 12\n",
    "    days_in_each_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "\n",
    "\n",
    "    Qmonthly = Array{Array}(undef, num_sites)\n",
    "    for i = 1:num_sites\n",
    "       Qmonthly[i] = zeros(Float64, num_years, num_months)\n",
    "    end\n",
    "\n",
    "    for yr = 1:num_years\n",
    "        for mo = 1:num_months\n",
    "            start = convert(Int, (yr - 1) * 365 + sum(days_in_each_month[1:(mo - 1)]) + 1)\n",
    "            \n",
    "            for i = 1:num_sites\n",
    "                Qmonthly[i][convert(Int, yr), mo] = 86400 * sum(Qt[start:start + days_in_each_month[mo] - 1, i])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return Qmonthly\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "monthly_main (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function monthly_main( hist_data, nR, nY)\n",
    "\n",
    "    num_years  = size(hist_data, 1) / 365\n",
    "    num_sites  = size(hist_data, 2)\n",
    "\n",
    "    # from daily to monthly\n",
    "    Qh = convert_data_to_monthly(hist_data)\n",
    "    \n",
    "    # initialize output\n",
    "    qq = Array{Array}(undef, num_sites)  #(4, 100, 1200)\n",
    "\n",
    "    for i = 1:num_sites\n",
    "       qq[i] =  Array{Float64}(undef, nR, nY * 12)\n",
    "    end\n",
    "\n",
    "    #     generate data\n",
    "    for r = 1:nR\n",
    "        Qs = monthly_gen(Qh, nY)\n",
    "\n",
    "        for k = 1:num_sites\n",
    "            qq[k][r, :] = reshape(Qs[1], 1, :)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return qq\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNN_identification (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function KNN_identification(Z, Qtotals, month)\n",
    "    # [KNN_id, W] = KNN_identification[ Z, Qtotals, month, k ]\n",
    "    #\n",
    "    # Identification of K-nearest neighbors of Z in the historical annual data\n",
    "    # z and computation of the associated weights W.\n",
    "    #\n",
    "    # Input:    Z = synthetic datum [scalar]\n",
    "    #           Qtotals = total monthly flows at all sites for all historical months\n",
    "    #             within +/- 7 days of the month being disaggregated\n",
    "    #           month = month being disaggregated\n",
    "    #           k = number of nearest neighbors (by default k=n_year^0.5\n",
    "    #             according to Lall and Sharma [1996])\n",
    "    # Output:   KNN_id = indices of the first K-nearest neighbors of Z in the\n",
    "    #             the historical annual data z\n",
    "    #           W = nearest neighbors weights, according to Lall and Sharma\n",
    "    #             (1996): W[i] = (1/i) / (sum(1/i))\n",
    "    #\n",
    "    #\n",
    "\n",
    "    # Ntotals is the number of historical monthly patterns used for disaggregation.\n",
    "    # A pattern is a sequence of ndays of daily flows, where ndays is the\n",
    "    # number of days in the month being disaggregated. Patterns are all()\n",
    "    # historical sequences of length ndays beginning within 7 days before or\n",
    "    # after the 1st day of the month being disaggregated.\n",
    "\n",
    "    # nearest neighbors identification\n",
    "    # only look at neighbors from the same month +/- 7 days\n",
    "    n_sites  = size(Qtotals[1][1], 2)\n",
    "    n_totals = size(Qtotals[1][1], 1)\n",
    "\n",
    "    k = Int(round(sqrt(n_totals)))\n",
    "\n",
    "    \n",
    "    delta = zeros(n_totals)     # first and last month have 7 less possible shifts\n",
    "    for i = 1:n_totals\n",
    "        for j = 1:n_sites\n",
    "            delta[i] += (Qtotals[month][j][i] - Z[j]) ^ 2\n",
    "        end\n",
    "    end\n",
    "\n",
    "    #create array with [index, delta_value] then sort\n",
    "    Y = [collect(1:size(delta, 1))', delta]\n",
    "    sort!(Y, by = x -> x[2])\n",
    "\n",
    "    KNN_id = zeros(Int(k))\n",
    "    \n",
    "    \n",
    "    for i in 1:Int(k)\n",
    "        KNN_id[i] = Y[1][i]\n",
    "    end\n",
    "\n",
    "    \n",
    "    # computation of the weights\n",
    "    f = zeros(k)\n",
    "    count_f = 0\n",
    "    \n",
    "    for i = 1:k\n",
    "        count_f += 1\n",
    "        f[i] = 1 / count_f\n",
    "    end\n",
    "\n",
    "    weights = f ./ sum(f)\n",
    "\n",
    "    return KNN_id, weights\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "combined_generator (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function combined_generator(hist_data, nR, nY)\n",
    "\n",
    "    num_sites = size(hist_data, 2)\n",
    "\n",
    "\n",
    "    # generation of monthly data via Kirsch et al. (2013):\n",
    "    # Kirsch, B. R., G. W. Characklis, and H. B. Zeff [2013],\n",
    "    # Evaluating the impact of alternative hydro-climate scenarios on transfer\n",
    "    # agreements: Practical improvement for generating synthetic streamflows,\n",
    "    # Journal of Water Resources Planning and Management, 139[4], 396â€“406.\n",
    "    QQg       = monthly_main(hist_data, nR, nY)\n",
    "    Qh        = convert_data_to_monthly(hist_data)\n",
    "    num_years = size(Qh[1], 1)\n",
    "\n",
    "\n",
    "    # disaggregation from monthly to daily time step as in Nowak et al. (2010):\n",
    "    # Nowak, K., Prairie, J., Rajagopalan, B., & Lall, U. (2010).\n",
    "    # A nonparametric stochastic approach for multisite disaggregation of\n",
    "    # annual to daily streamflow. Water Resources Research, 46[8].\n",
    "\n",
    "    # Find K-nearest neighbors [KNN] in terms of total monthly flow and\n",
    "    # randomly select one for disaggregation. Proportionally scale the flows in\n",
    "    # the selected neighbor to match the synthetic monthly total. To\n",
    "    # disaggregate Jan Flows, consider all historical January totals +/- 7\n",
    "    # days, etc.\n",
    "    \n",
    "    Dt    = 3600 * 24\n",
    "    D     = Array{Array}(undef, nR)\n",
    "    dd    = zeros(num_sites, 365)\n",
    "    nrows = size(hist_data, 1)\n",
    "    \n",
    "    days_in_each_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "\n",
    "    \n",
    "    # concatenate last 7 days of last year before first 7 days of first year\n",
    "    # and first 7 days of first year after last 7 days of last year\n",
    "    extra_hist_data = [hist_data[nrows-7:nrows,:]; hist_data; hist_data[1:8,:]]\n",
    "\n",
    "\n",
    "    Qtotals  = Array{Array}(undef, 12)\n",
    "    Qindices = Array{Array}(undef, 12)\n",
    "\n",
    "    \n",
    "    # find monthly totals for all months +/- 7 days\n",
    "    for i = 1:12\n",
    "        count = 0\n",
    "\n",
    "        if i == 1 || i == 12\n",
    "            nTotals = num_years * 15 - 7     # 7 fewer shifts in first and last month\n",
    "        else\n",
    "            nTotals = num_years * 15\n",
    "        end\n",
    "\n",
    "        \n",
    "        Qh_neg           = zeros(size(Qh[1], 1) - 1)\n",
    "        Qmonthly_shifted = Array{Array}(undef, num_sites)\n",
    "        indices          = [[2], [1]]\n",
    "        \n",
    "        \n",
    "        for k = 1:15\n",
    "            shifted_hist_data = extra_hist_data[k: k + nrows - 1, :]  \n",
    "            Qh                = convert_data_to_monthly(shifted_hist_data)\n",
    "\n",
    "            for j = 1:num_sites\n",
    "                if i == 1 && k < 8\n",
    "                    for f = 1:size(Qh[j], 1) - 1\n",
    "                        Qh_neg[f] = Qh[j][f + 1, i]     # remove first year\n",
    "                    end\n",
    "                \n",
    "                elseif i == 12 && k > 8\n",
    "                    for f = 1:(size(Qh[j], 1) - 1)\n",
    "                        Qh_neg[f] = Qh[j][f, i]  # remove last year\n",
    "                    end\n",
    "                end\n",
    "\n",
    "\n",
    "                if count == 0\n",
    "                    new_matrix          = deepcopy(Qh_neg)\n",
    "                    Qmonthly_shifted[j] = deepcopy(Qh_neg)\n",
    "                \n",
    "                else\n",
    "                    new_matrix          = vcat(Qmonthly_shifted[j], Qh_neg)\n",
    "                    Qmonthly_shifted[j] = new_matrix\n",
    "                end\n",
    "            end\n",
    "\n",
    "            if i == 1 && k < 8\n",
    "                indices[1] = [2]\n",
    "                indices[2] = [1]\n",
    "                append!(indices[1], collect(2:(size(Qh[1], 1))))\n",
    "                append!(indices[2], fill(2, (size(Qh[1], 1) - 2, 1)))\n",
    "            \n",
    "            else\n",
    "                append!(indices[1], collect(1:1:(size(Qh[1], 1) + 1)))\n",
    "                append!(indices[2], fill(2, (size(Qh[1], 1), 1)))\n",
    "            end\n",
    "\n",
    "            count = count + size(Qh[1], 1)\n",
    "        end\n",
    "\n",
    "        Qtotals[i]  =  Qmonthly_shifted\n",
    "        Qindices[i] = indices  \n",
    "    end\n",
    "\n",
    "    println(\"Starting synthetic generation for $nR realization and $nY years\")\n",
    "    \n",
    "    for r = 1:nR\n",
    "        count_count = 0\n",
    "        \n",
    "        for i = 1:nY * 12\n",
    "            # monthly value for all sites\n",
    "            Z = Array{Float64}(undef, num_sites)\n",
    "            \n",
    "            for v = 1:num_sites\n",
    "                Z[v] = QQg[v][r, i]\n",
    "            end\n",
    "\n",
    "            #KNN and weights\n",
    "            month = mod(i, 12)\n",
    "            if month == 0\n",
    "                month = 12\n",
    "            end\n",
    "\n",
    "            KNN_id, W = KNN_identification(Z, Qtotals, month)\n",
    "            Wcum      = cumsum(W)\n",
    "\n",
    "            #sampling of one KNN    \n",
    "            py = KNN_sampling(KNN_id, Qindices[month], Wcum, hist_data, month)[1]\n",
    "            d  = Array{Float64}(undef, num_sites, size(py, 1))\n",
    "\n",
    "            for j = 1:Int(num_sites)\n",
    "                new_d   = reshape(py[:, j], size(py, 1), :) * Z[j] / Dt\n",
    "                d[j, :] =  new_d'\n",
    "            end\n",
    "\n",
    "            \n",
    "            if count_count != 0\n",
    "                dd = hcat(dd, d)\n",
    "            \n",
    "            else\n",
    "                dd = similar(d)\n",
    "                dd =  d\n",
    "            end\n",
    "\n",
    "            count_count += 1\n",
    "        end\n",
    "\n",
    "        dd   = dd\n",
    "        D[r] = dd' #dims(nR)(, num_sites, )\n",
    "    end\n",
    "\n",
    "    return D\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "monthly_gen (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function monthly_gen(Q_historical, num_years)\n",
    "\n",
    "    num_points = length(Q_historical)\n",
    "    num_Q_hist = length(Q_historical[1][:,1])\n",
    "\n",
    "    #error checking\n",
    "    for i = 2:num_points\n",
    "        if length(Q_historical[i][:,1]) != num_Q_hist\n",
    "            error(\"All matrices in Q_historical must be the same size.\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    num_years     = num_years + 1      #adjusts for their new corr technique\n",
    "    nQ            = num_Q_hist\n",
    "    random_matrix = rand(1:nQ, num_years, 12)\n",
    "    Qs            = Array{Array}(undef, num_points)\n",
    "\n",
    "    for k = 1: num_points\n",
    "        Q_matrix = Q_historical[k]\n",
    "        logQ     = log.(Q_matrix)\n",
    "\n",
    "        monthly_mean  = zeros(1, 12)\n",
    "        monthly_stdev = zeros(1, 12)\n",
    "        Z             = zeros(nQ, 12)\n",
    "\n",
    "\n",
    "        for i = 1:12\n",
    "            monthly_mean[i]  = mean(logQ[:, i])\n",
    "            monthly_stdev[i] = Statistics.std(logQ[:, i])\n",
    "            \n",
    "            Z[:,i] = (logQ[:, i] .- monthly_mean[i]) ./ monthly_stdev[i]\n",
    "        end\n",
    "\n",
    "\n",
    "        Z_vector  = reshape(Z', 1, :)\n",
    "        Z_shifted = reshape(Z_vector[7:(nQ * 12 - 6)], 12, :)'\n",
    "\n",
    "\n",
    "        # The correlation matrices should use the historical Z's\n",
    "        # (the \"appended years\" do not preserve correlation)\n",
    "        U         = cholesky_corr(Z[1:num_Q_hist, :])\n",
    "        U_shifted = cholesky_corr(Z_shifted[1: num_Q_hist - 1, :])\n",
    "        \n",
    "        \n",
    "        Qs_uncorr = zeros(12, num_years)\n",
    "        for i = 1:12\n",
    "            Qs_uncorr[i, :] = Z[random_matrix[:, i], i]\n",
    "        end\n",
    "        \n",
    "        Qs_uncorr          = reshape(Qs_uncorr, :, 12)\n",
    "        Qs_uncorr_vector   = reshape(Qs_uncorr[:, :]', 1, :)\n",
    "        Qs_uncorr_shifted  = reshape(Qs_uncorr_vector[7:(num_years * 12 - 6)], 12, :)'\n",
    "\n",
    "\n",
    "        Qs_uncorr = Qs_uncorr * I\n",
    "        U         = U * I\n",
    "        Qs_corr   = Qs_uncorr * U\n",
    "\n",
    "        \n",
    "        U_shifted          = U_shifted * I\n",
    "        Qs_uncorr_shifted  = Qs_uncorr_shifted * I\n",
    "        Qs_corr_shifted    = Qs_uncorr_shifted * U_shifted\n",
    "\n",
    "        \n",
    "        Qs_log          = similar(Qs_corr_shifted)\n",
    "        Qs_log[:, 1:6]  = Qs_corr_shifted[:, 7:12]\n",
    "        Qs_log[:, 7:12] = Qs_corr[2:num_years, 7:12]\n",
    "        Qsk             = Array{Float64}(undef, 12, num_years - 1)\n",
    "\n",
    "        \n",
    "        for i = 1:12\n",
    "            add_element = reshape(exp.(Qs_log[:, i] .* monthly_stdev[i] .+ monthly_mean[i]), 1, :)\n",
    "            Qsk[i, :]   = add_element[:, :]\n",
    "        end\n",
    "\n",
    "        Qsk   = transpose(Qsk)\n",
    "        Qs[k] = Qsk'\n",
    "    end\n",
    "\n",
    "   return Qs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNN_sampling (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function KNN_sampling(KNN_id, indices, weights_cumm, Qdaily, month)\n",
    "    # py = KNN_sampling[ KKN_id, indices, Wcum, Qdaily, month ]\n",
    "    #\n",
    "    # Selection of one KNN according to the probability distribution defined by\n",
    "    # the weights W.\n",
    "    #\n",
    "    # Input:    KNN_id = indices of the first K-nearest neighbors\n",
    "    #           indices = n x 2 matrix where n is the number of monthly totals\n",
    "    #             and the 2 columns store the historical year in which each\n",
    "    #             monthly total begins, and the number of shift index\n",
    "    #             where 1 is 7 days earlier and 15 is 7 days later\n",
    "    #           Wcum = cumulated probability for each nearest neighbor\n",
    "    #           Qdaily = historical data\n",
    "    #           month = month being disaggregated\n",
    "    # Output:   py = selected proportion vector corresponding to the sampled\n",
    "    #             shifted historical month\n",
    "    #           yearID = randomly selected monthly total [row to select from indices]\n",
    "    #\n",
    "    #\n",
    "\n",
    "    #Randomly select one of the k-NN using the Lall and Sharma density\n",
    "    #estimator\n",
    "    r                  = rand()\n",
    "    KNNs               = 0\n",
    "    days_in_each_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "\n",
    "    prepend!(weights_cumm, 0)\n",
    "\n",
    "    for i = 1:length(weights_cumm)-1\n",
    "        if(r > weights_cumm[i]) && (r <= weights_cumm[i + 1])\n",
    "            KNNs = i\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "    yearID = Int(KNN_id[KNNs])\n",
    "\n",
    "    # concatenate last 7 days of last year before first 7 days of first year\n",
    "    # and first 7 days of first year after last 7 days of last year\n",
    "    nrows  = size(Qdaily, 1)\n",
    "    QDaily = [Qdaily[nrows-7:nrows,:]; Qdaily; Qdaily[1:8,:]]\n",
    "\n",
    "\n",
    "    #shift historical data to get nearest neighbor corresponding to yearID\n",
    "    year           = Int(indices[1][yearID])\n",
    "    k              = Int(indices[2][yearID])\n",
    "    lower          = Int(max(k, 1))\n",
    "    upper          = Int(floor(min(k + nrows - 1, size(QDaily, 1) * 0.97)))\n",
    "    shifted_Qdaily = Qdaily[lower:upper, :]\n",
    "\n",
    "\n",
    "\n",
    "    start       = (year - 1) * 365 + sum(days_in_each_month[1:(month - 1)]) + 1\n",
    "    daily_flows = shifted_Qdaily[start:start + days_in_each_month[month] - 1, :]\n",
    "    py          = zeros(size(daily_flows, 1), size(daily_flows, 2))\n",
    "\n",
    "\n",
    "    for i = 1:size(QDaily, 2)\n",
    "        py[:, i] = daily_flows[:, i] / sum(daily_flows[:, i])\n",
    "    end\n",
    "\n",
    "    return py, yearID\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################\n",
    "#### USER INPUT FOR OUTPUT FILES#######\n",
    "#### Iterates through both arrays######\n",
    "#######################################\n",
    "num_realizations = [10, 10, 10, 10 , 10  , 100, 100, 100, 1000, 1000, 1000]\n",
    "num_years =        [10, 1 , 10, 100, 1000, 1  , 10 , 100, 1   , 10  , 100 ]\n",
    "#######################################\n",
    "#######################################\n",
    "\n",
    "# Importing data\n",
    "datadir     = pwd() * \"/data/\"\n",
    "Qdaily      = CSV.read(datadir*\"Qdaily.txt\", delim=\" \")\n",
    "Qdaily      = convert(Matrix, Qdaily)[:, 1:4]\n",
    "Qdaily[:,4] = log.(Qdaily[:,4])\n",
    "\n",
    "sites  = [\"qMarietta\", \"qMuddyRun\", \"qLateral\", \"evapConowingo\"]\n",
    "Nyears = size(Qdaily, 1) / 365\n",
    "Nsites = size(Qdaily, 2)\n",
    "\n",
    "\n",
    "#check if directory for output is available. Create if it isn't.\n",
    "if isdir(datadir*\"\\\\output\\\\\")\n",
    "    x=1\n",
    "else\n",
    "    mkdir(datadir*\"\\\\output\\\\\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic generation for 10 realization and 10 years\n",
      "  6.273389 seconds (21.90 M allocations: 3.172 GiB, 9.56% gc time)\n",
      "Finished 10 realizations over 10 years for qMarietta.\n",
      "Finished 10 realizations over 10 years for qMuddyRun.\n",
      "Finished 10 realizations over 10 years for qLateral.\n",
      "Finished 10 realizations over 10 years for evapConowingo.\n",
      "Starting synthetic generation for 10 realization and 1 years\n",
      "  0.480005 seconds (2.67 M allocations: 669.932 MiB, 14.90% gc time)\n",
      "Finished 10 realizations over 1 years for qMarietta.\n",
      "Finished 10 realizations over 1 years for qMuddyRun.\n",
      "Finished 10 realizations over 1 years for qLateral.\n",
      "Finished 10 realizations over 1 years for evapConowingo.\n",
      "Starting synthetic generation for 10 realization and 10 years\n",
      "  2.482972 seconds (14.08 M allocations: 2.799 GiB, 15.24% gc time)\n",
      "Finished 10 realizations over 10 years for qMarietta.\n",
      "Finished 10 realizations over 10 years for qMuddyRun.\n",
      "Finished 10 realizations over 10 years for qLateral.\n",
      "Finished 10 realizations over 10 years for evapConowingo.\n",
      "Starting synthetic generation for 10 realization and 100 years\n",
      " 19.423634 seconds (128.28 M allocations: 30.062 GiB, 14.11% gc time)\n",
      "Finished 10 realizations over 100 years for qMarietta.\n",
      "Finished 10 realizations over 100 years for qMuddyRun.\n",
      "Finished 10 realizations over 100 years for qLateral.\n",
      "Finished 10 realizations over 100 years for evapConowingo.\n",
      "Starting synthetic generation for 10 realization and 1000 years\n",
      "503.553801 seconds (1.27 G allocations: 884.219 GiB, 19.56% gc time)\n",
      "Finished 10 realizations over 1000 years for qMarietta.\n",
      "Finished 10 realizations over 1000 years for qMuddyRun.\n",
      "Finished 10 realizations over 1000 years for qLateral.\n",
      "Finished 10 realizations over 1000 years for evapConowingo.\n",
      "Starting synthetic generation for 100 realization and 1 years\n",
      "  2.017183 seconds (14.21 M allocations: 2.773 GiB, 10.01% gc time)\n",
      "Finished 100 realizations over 1 years for qMarietta.\n",
      "Finished 100 realizations over 1 years for qMuddyRun.\n",
      "Finished 100 realizations over 1 years for qLateral.\n",
      "Finished 100 realizations over 1 years for evapConowingo.\n",
      "Starting synthetic generation for 100 realization and 10 years\n",
      " 17.722403 seconds (128.38 M allocations: 24.220 GiB, 9.60% gc time)\n",
      "Finished 100 realizations over 10 years for qMarietta.\n",
      "Finished 100 realizations over 10 years for qMuddyRun.\n",
      "Finished 100 realizations over 10 years for qLateral.\n",
      "Finished 100 realizations over 10 years for evapConowingo.\n",
      "Starting synthetic generation for 100 realization and 100 years\n",
      "176.753937 seconds (1.27 G allocations: 296.846 GiB, 10.58% gc time)\n",
      "Finished 100 realizations over 100 years for qMarietta.\n",
      "Finished 100 realizations over 100 years for qMuddyRun.\n",
      "Finished 100 realizations over 100 years for qLateral.\n",
      "Finished 100 realizations over 100 years for evapConowingo.\n",
      "Starting synthetic generation for 1000 realization and 1 years\n",
      " 16.452206 seconds (129.68 M allocations: 23.966 GiB, 8.86% gc time)\n",
      "Finished 1000 realizations over 1 years for qMarietta.\n",
      "Finished 1000 realizations over 1 years for qMuddyRun.\n",
      "Finished 1000 realizations over 1 years for qLateral.\n",
      "Finished 1000 realizations over 1 years for evapConowingo.\n",
      "Starting synthetic generation for 1000 realization and 10 years\n",
      "148.867903 seconds (1.27 G allocations: 238.438 GiB, 9.39% gc time)\n",
      "Finished 1000 realizations over 10 years for qMarietta.\n",
      "Finished 1000 realizations over 10 years for qMuddyRun.\n",
      "Finished 1000 realizations over 10 years for qLateral.\n",
      "Finished 1000 realizations over 10 years for evapConowingo.\n",
      "Starting synthetic generation for 1000 realization and 100 years\n",
      "1610.731985 seconds (12.69 G allocations: 2.895 TiB, 10.38% gc time)\n",
      "Finished 1000 realizations over 100 years for qMarietta.\n",
      "Finished 1000 realizations over 100 years for qMuddyRun.\n",
      "Finished 1000 realizations over 100 years for qLateral.\n",
      "Finished 1000 realizations over 100 years for evapConowingo.\n",
      "3109.997287 seconds (17.06 G allocations: 4.974 TiB, 11.99% gc time)\n"
     ]
    }
   ],
   "source": [
    "#Note that @time is used to calculate the time for each function\n",
    "#the final time will be displayed at end of all outputs\n",
    "@time for k = 1:length(num_realizations)\n",
    "    \n",
    "    #put data and parameters into generator\n",
    "    @time Qd_cg = combined_generator(Qdaily, num_realizations[k], num_years[k]) \n",
    "    \n",
    "    #back-transform data\n",
    "    for i = 1:size(Qd_cg, 1)\n",
    "        Qd_cg[i][:, 4] = log.(Qd_cg[i][:, 4])\n",
    "    end\n",
    "\n",
    "    #initialize blank arrays\n",
    "    Qd2       = zeros(365 * num_years[k] * num_realizations[k])\n",
    "    q_        = Array{Float64, 2}(undef, num_realizations[k], 365 * num_years[k])\n",
    "    Q_monthly = zeros(num_realizations[k] * num_years[k], 12)\n",
    "    \n",
    "    for i = 1: Nsites\n",
    "        # put into array of [realizations, 365*num_yrs]\n",
    "        for j = 1: num_realizations[k]\n",
    "            q_[j, :] = Qd_cg[j][:, i]'\n",
    "        end\n",
    "        \n",
    "\n",
    "        # write to csv for daily\n",
    "        file_name = datadir * \"\\\\output\\\\\" * sites[i] *string(num_realizations[k]) * \"x\" * string(num_years[k]) * \"_daily.csv\"\n",
    "        \n",
    "        CSV.write(file_name, Tables.table(q_), writeheader=false)\n",
    "\n",
    "        \n",
    "        #convert to monthly, then write to csv\n",
    "        Qd2             = reshape(q_, :, 1)\n",
    "        Q_monthly[:, :] = convert_data_to_monthly(Qd2)[1]\n",
    "        file_name       = datadir * \"\\\\output\\\\\" * sites[i] *string(num_realizations[k]) * \"x\" * string(num_years[k]) * \"_monthly.csv\"\n",
    "        \n",
    "        CSV.write(file_name, Tables.table(Q_monthly), writeheader=false)\n",
    "\n",
    "        println(\"Finished $(num_realizations[k]) realizations over $(num_years[k]) years for $(sites[i]).\")\n",
    "\n",
    "    end\n",
    "    \n",
    "    #output entire daily record to csv\n",
    "    file_name   = datadir * \"\\\\output\\\\\" * \"Qdaily\" * string(num_realizations[k]) * \"x\" * string(num_years[k]) * \".csv\"\n",
    "    output_file = deepcopy(Qd_cg[1])\n",
    "\n",
    "    for i = 2:size(Qd_cg, 1)\n",
    "        output_file = [output_file; Qd_cg[i]]\n",
    "    end\n",
    "\n",
    "    CSV.write(file_name, Tables.table(output_file), writeheader=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_synth (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing speeds using a function\n",
    "function run_synth(num_realizations, num_years)\n",
    "    #put data and parameters into generator\n",
    "    Qd_cg = combined_generator(Qdaily, num_realizations, num_years) \n",
    "\n",
    "    #back-transform data\n",
    "    for i = 1:size(Qd_cg, 1)\n",
    "        Qd_cg[i][:, 4] = log.(Qd_cg[i][:, 4])\n",
    "    end\n",
    "\n",
    "    #initialize blank arrays\n",
    "    Qd2       = zeros(365 * num_years * num_realizations)\n",
    "    q_        = Array{Float64, 2}(undef, num_realizations, 365 * num_years)\n",
    "    Q_monthly = zeros(num_realizations * num_years, 12)\n",
    "\n",
    "    for i = 1: Nsites\n",
    "        # put into array of [realizations, 365*num_yrs]\n",
    "        for j = 1: num_realizations\n",
    "            q_[j, :] = Qd_cg[j][:, i]'\n",
    "        end\n",
    "\n",
    "\n",
    "        # write to csv for daily\n",
    "        file_name = datadir * \"\\\\output\\\\\" * sites[i] *string(num_realizations) * \"x\" * string(num_years) * \"_daily.csv\"\n",
    "\n",
    "        CSV.write(file_name, Tables.table(q_), writeheader=false)\n",
    "\n",
    "\n",
    "        #convert to monthly, then write to csv\n",
    "        Qd2             = reshape(q_, :, 1)\n",
    "        Q_monthly[:, :] = convert_data_to_monthly(Qd2)[1]\n",
    "        file_name       = datadir * \"\\\\output\\\\\" * sites[i] *string(num_realizations) * \"x\" * string(num_years) * \"_monthly.csv\"\n",
    "\n",
    "        CSV.write(file_name, Tables.table(Q_monthly), writeheader=false)\n",
    "\n",
    "        println(\"Finished $(num_realizations) realizations over $(num_years) years for $(sites[i]).\")\n",
    "\n",
    "    end\n",
    "\n",
    "    #output entire daily record to csv\n",
    "    file_name   = datadir * \"\\\\output\\\\\" * \"Qdaily\" * string(num_realizations) * \"x\" * string(num_years) * \".csv\"\n",
    "    output_file = deepcopy(Qd_cg[1])\n",
    "\n",
    "    for i = 2:size(Qd_cg, 1)\n",
    "        output_file = [output_file; Qd_cg[i]]\n",
    "    end\n",
    "\n",
    "    CSV.write(file_name, Tables.table(output_file), writeheader=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic generation for 10000 realization and 1 years\n",
      "Finished 10000 realizations over 1 years for qMarietta.\n",
      "Finished 10000 realizations over 1 years for qMuddyRun.\n",
      "Finished 10000 realizations over 1 years for qLateral.\n",
      "Finished 10000 realizations over 1 years for evapConowingo.\n",
      "534.489341 seconds (1.29 G allocations: 780.533 GiB, 17.38% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"E:\\\\Dropbox\\\\Dropbox\\\\Reed Group Work\\\\Blog Posts\\\\stationary_synth_streamflow_julia/data/\\\\output\\\\Qdaily10000x1.csv\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time run_synth(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic generation for 10000 realization and 10 years\n",
      "Finished 10000 realizations over 10 years for qMarietta.\n",
      "Finished 10000 realizations over 10 years for qMuddyRun.\n",
      "Finished 10000 realizations over 10 years for qLateral.\n",
      "Finished 10000 realizations over 10 years for evapConowingo.\n",
      "4653.323496 seconds (12.77 G allocations: 7.643 TiB, 15.02% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"E:\\\\Dropbox\\\\Dropbox\\\\Reed Group Work\\\\Blog Posts\\\\stationary_synth_streamflow_julia/data/\\\\output\\\\Qdaily10000x10.csv\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time run_synth(10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic generation for 100 realization and 100 years\n",
      "Finished 100 realizations over 100 years for qMarietta.\n",
      "Finished 100 realizations over 100 years for qMuddyRun.\n",
      "Finished 100 realizations over 100 years for qLateral.\n",
      "Finished 100 realizations over 100 years for evapConowingo.\n",
      "215.057785 seconds (1.30 G allocations: 304.044 GiB, 10.53% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"E:\\\\Dropbox\\\\Dropbox\\\\Reed Group Work\\\\Blog Posts\\\\stationary_synth_streamflow_julia/data/\\\\output\\\\Qdaily100x100.csv\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time run_synth(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic generation for 100 realization and 100 years\n",
      "Finished 100 realizations over 100 years for qMarietta.\n",
      "Finished 100 realizations over 100 years for qMuddyRun.\n",
      "Finished 100 realizations over 100 years for qLateral.\n",
      "Finished 100 realizations over 100 years for evapConowingo.\n",
      "193.274922 seconds (1.28 G allocations: 303.082 GiB, 10.71% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"E:\\\\Dropbox\\\\Dropbox\\\\Reed Group Work\\\\Blog Posts\\\\stationary_synth_streamflow_julia/data/\\\\output\\\\Qdaily100x100.csv\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time run_synth(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic generation for 1 realization and 51 years\n",
      "Finished 1 realizations over 51 years for qMarietta.\n",
      "Finished 1 realizations over 51 years for qMuddyRun.\n",
      "Finished 1 realizations over 51 years for qLateral.\n",
      "Finished 1 realizations over 51 years for evapConowingo.\n",
      "  2.461490 seconds (9.31 M allocations: 1.830 GiB, 7.24% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"E:\\\\Dropbox\\\\Dropbox\\\\Reed Group Work\\\\Blog Posts\\\\stationary_synth_streamflow_julia/data/\\\\output\\\\Qdaily1x51.csv\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time run_synth(1, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic generation for 10 realization and 51 years\n",
      "Finished 10 realizations over 51 years for qMarietta.\n",
      "Finished 10 realizations over 51 years for qMuddyRun.\n",
      "Finished 10 realizations over 51 years for qLateral.\n",
      "Finished 10 realizations over 51 years for evapConowingo.\n",
      " 12.500325 seconds (67.22 M allocations: 14.012 GiB, 10.94% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"E:\\\\Dropbox\\\\Dropbox\\\\Reed Group Work\\\\Blog Posts\\\\stationary_synth_streamflow_julia/data/\\\\output\\\\Qdaily10x51.csv\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time run_synth(10, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic generation for 100 realization and 51 years\n",
      "Finished 100 realizations over 51 years for qMarietta.\n",
      "Finished 100 realizations over 51 years for qMuddyRun.\n",
      "Finished 100 realizations over 51 years for qLateral.\n",
      "Finished 100 realizations over 51 years for evapConowingo.\n",
      "102.296224 seconds (652.66 M allocations: 138.487 GiB, 11.94% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"E:\\\\Dropbox\\\\Dropbox\\\\Reed Group Work\\\\Blog Posts\\\\stationary_synth_streamflow_julia/data/\\\\output\\\\Qdaily100x51.csv\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time run_synth(100, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic generation for 1000 realization and 51 years\n",
      "Finished 1000 realizations over 51 years for qMarietta.\n",
      "Finished 1000 realizations over 51 years for qMuddyRun.\n",
      "Finished 1000 realizations over 51 years for qLateral.\n",
      "Finished 1000 realizations over 51 years for evapConowingo.\n",
      "1480.788847 seconds (6.51 G allocations: 1.592 TiB, 10.69% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"E:\\\\Dropbox\\\\Dropbox\\\\Reed Group Work\\\\Blog Posts\\\\stationary_synth_streamflow_julia/data/\\\\output\\\\Qdaily1000x51.csv\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time run_synth(1000, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
